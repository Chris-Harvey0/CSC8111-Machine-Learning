{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNLg1aP8Am37fDPVmrMN0TZ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hmBNpx0fWOqk","executionInfo":{"status":"ok","timestamp":1670727260345,"user_tz":0,"elapsed":1943,"user":{"displayName":"Christopher Harvey","userId":"03665955858934014968"}},"outputId":"0d8c3f42-5a16-4144-f174-1309ca1f33f4"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","import pandas as pd\n","import numpy as np\n","\n","# Load text datasets from Google Drive\n","path = \"/content/drive/MyDrive/CSC8111_Coursework/\" # Change path to run program\n","\n","train = pd.read_csv(path + \"Tweets_train.csv\", encoding=\"ISO-8859-1\")\n","test = pd.read_csv(path + \"Tweets_test.csv\", encoding=\"ISO-8859-1\")\n","dev = pd.read_csv(path + \"Tweets_dev.csv\", encoding=\"ISO-8859-1\")\n","\n","train = train.to_numpy()\n","test = test.to_numpy()\n","dev = dev.to_numpy()"]},{"cell_type":"code","source":["combined_array = train\n","combined_array = np.r_[combined_array, test]\n","combined_array = np.r_[combined_array, dev]"],"metadata":{"id":"Gg9itA8RWf97"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def create_arrays(array):\n","  array_x = []\n","  array_y = []\n","\n","  count_pos = 0\n","  count_neu = 0\n","  count_neg = 0\n","\n","  for value in array:\n","    array_x.append(value[1])\n","    array_y.append(value[2])\n","    if value[2] == \"positive\": count_pos += 1\n","    elif value[2] == \"neutral\": count_neu += 1\n","    elif value[2] == \"negative\": count_neg += 1\n","\n","  print(\"Positive count: %d\" % count_pos)\n","  print(\"Neutral count: %d\" % count_neu)\n","  print(\"Negative count: %d\" % count_neg)\n","\n","  array_x = np.array(array_x, dtype=object)\n","  array_y = np.array(array_y, dtype=object)\n","\n","  return array_x, array_y"],"metadata":{"id":"Oii6BKOnWjpt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from nltk.sem.logic import Tokens\n","import nltk\n","nltk.download(\"stopwords\")\n","from nltk.corpus import stopwords\n","import string\n","\n","def clean_array(array):\n","  clean_array = []\n","  for tweet in array:\n","    # Split tweet into words\n","    tokens = tweet.split()\n","    # Remove @ tags\n","    tokens = [word for word in tokens if word[0] != \"@\"]\n","    # Remove punctuation\n","    remove_table = str.maketrans(\"\", \"\", string.punctuation)\n","    tokens = [word.translate(remove_table) for word in tokens]\n","    # Remove non-alphabetic words\n","    tokens = [word for word in tokens if word.isalpha()]\n","    # Remove stop words\n","    stop_words = set(stopwords.words('english'))\n","    tokens = [word for word in tokens if not word in stop_words]\n","    # Remove one character words\n","    tokens = [word for word in tokens if len(word) > 1]\n","    # Convert all characters to lower case\n","    tokens = [word.lower() for word in tokens]\n","    # Join words back together into single string\n","    clean_array.append(\" \".join(tokens))\n","  clean_array = np.array(clean_array, dtype=object)\n","  \n","  return clean_array"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"403yDU36Wl3S","executionInfo":{"status":"ok","timestamp":1670727260347,"user_tz":0,"elapsed":10,"user":{"displayName":"Christopher Harvey","userId":"03665955858934014968"}},"outputId":"63c3ab2e-9184-47ad-aa1e-96b9625d9ba9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"]}]},{"cell_type":"code","source":["combined_array_x, combined_array_y = create_arrays(combined_array)\n","combined_array_x = clean_array(combined_array_x)"],"metadata":{"id":"YnRQhyTZY0EL","executionInfo":{"status":"ok","timestamp":1670727262828,"user_tz":0,"elapsed":2489,"user":{"displayName":"Christopher Harvey","userId":"03665955858934014968"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"3ee853de-cb79-4ecd-cc64-562430e0e1a2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Positive count: 2363\n","Neutral count: 3099\n","Negative count: 9178\n"]}]},{"cell_type":"code","source":["from sklearn.feature_extraction.text import TfidfVectorizer\n","\n","vectorizer = TfidfVectorizer(max_features=5000)\n","vector_array_x = vectorizer.fit_transform(combined_array_x).toarray()"],"metadata":{"id":"ox_VKO5QWvWY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","\n","train_x, test_x, train_y, test_y = train_test_split(vector_array_x, combined_array_y, test_size=0.2)"],"metadata":{"id":"6WhaOr2-Zo6m"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.ensemble import RandomForestClassifier\n","\n","model = RandomForestClassifier(n_estimators=200)\n","model.fit(train_x, train_y)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KhQq_DVpaCod","executionInfo":{"status":"ok","timestamp":1670727429023,"user_tz":0,"elapsed":165611,"user":{"displayName":"Christopher Harvey","userId":"03665955858934014968"}},"outputId":"c410f7f1-9695-4fe0-89a4-a99d8048517b"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["RandomForestClassifier(n_estimators=200)"]},"metadata":{},"execution_count":142}]},{"cell_type":"code","source":["predictions = model.predict(test_x)\n","from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n","\n","print(confusion_matrix(test_y,predictions))\n","print(classification_report(test_y,predictions))\n","print(\"Accuracy: %.2f\" % (accuracy_score(test_y, predictions) * 100))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VWRkA_C1bjnD","executionInfo":{"status":"ok","timestamp":1670728109011,"user_tz":0,"elapsed":2569,"user":{"displayName":"Christopher Harvey","userId":"03665955858934014968"}},"outputId":"a5326691-9aad-4d63-e769-7c4896542055"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[1686  110   48]\n"," [ 267  295   44]\n"," [ 150   57  271]]\n","              precision    recall  f1-score   support\n","\n","    negative       0.80      0.91      0.85      1844\n","     neutral       0.64      0.49      0.55       606\n","    positive       0.75      0.57      0.64       478\n","\n","    accuracy                           0.77      2928\n","   macro avg       0.73      0.66      0.68      2928\n","weighted avg       0.76      0.77      0.76      2928\n","\n","Accuracy: 76.91\n"]}]}]}